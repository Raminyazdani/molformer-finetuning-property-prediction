Ramin Yazdani | molformer-finetuning-property-prediction | main | WIP(training): Add MLM and regression training loop

Implemented the core training loop combining masked language modeling (MLM) and 
regression objectives for fine-tuning MolFormer on the Lipophilicity dataset.

Training implementation:
- Dual objective: MLM for language understanding + regression for property prediction
- Adam optimizer with learning rate scheduling
- Training loop with gradient accumulation
- Loss tracking and logging
- Initial batch size: 32

This is the core functionality of the project, demonstrating transfer learning on chemical
language models. The implementation combines pre-training techniques (MLM) with task-specific
fine-tuning (regression) for enhanced performance.

Verification: Training loop implemented, ready for execution.
