Ramin Yazdani | molformer-finetuning-property-prediction | main | WIP(training): Note: Training fails with batch size 32 (OOM error)

Discovered during training execution that batch size 32 causes CUDA out of memory error
on the available GPU. The error occurs during forward pass:

  RuntimeError: CUDA out of memory. Tried to allocate X.XX GiB
  
This is extremely common in transformer model training. MolFormer-XL is a large model and
batch size 32 exceeds GPU memory capacity (likely 16GB or less).

Documented the issue before fixing to maintain realistic debugging narrative. The batch
size needs to be reduced to fit within hardware constraints.

Verification: Issue documented in notebook comment.
